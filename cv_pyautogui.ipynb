{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogui"
      ],
      "metadata": {
        "id": "fzkgLByTXeG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "id": "fYA-sJ_FXgvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "id": "fLdEvXqaXiq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#red ball\n",
        "\n",
        "import pyautogui\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_hands = mp.solutions.hands\n",
        "in_fi=[8]\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "with mp_hands.Hands(\n",
        "    model_complexity=0,\n",
        "    max_num_hands=1,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as hands:\n",
        "  while cap.isOpened():\n",
        "    success, image = cap.read()\n",
        "    if not success:\n",
        "      print(\"Ignoring empty camera frame.\")\n",
        "      continue\n",
        "\n",
        "\n",
        "    image.flags.writeable = False\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(image)\n",
        "\n",
        "    # Draw the hand annotations on the image.\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    if results.multi_hand_landmarks:\n",
        "      for hand_landmarks in results.multi_hand_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image,\n",
        "            hand_landmarks,\n",
        "            mp_hands.HAND_CONNECTIONS,\n",
        "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "            mp_drawing_styles.get_default_hand_connections_style())\n",
        "        xco=[]\n",
        "        yco=[]\n",
        "        zco=[]\n",
        "        for id,lms in enumerate(hand_landmarks.landmark):\n",
        "            ih,iw,ic = image.shape\n",
        "            x,y,z = int(lms.x*iw),int(lms.y*ih),int(lms.z*iw)\n",
        "            xco.append(x)\n",
        "            yco.append(y)\n",
        "            zco.append(z)\n",
        "\n",
        "\n",
        "\n",
        "        if yco[5]>yco[6]>yco[7]>yco[8]:\n",
        "            pyautogui.keyDown('w')\n",
        "        else:\n",
        "            pyautogui.keyUp('w')\n",
        "\n",
        "        if xco[1]<xco[2]<xco[3]<xco[4]:\n",
        "            pyautogui.keyDown('d')\n",
        "        else:\n",
        "            pyautogui.keyUp('d')\n",
        "\n",
        "        if zco[17]>zco[18]>zco[19]>zco[20]:\n",
        "            pyautogui.keyDown('a')\n",
        "        else:\n",
        "            pyautogui.keyUp('a')\n",
        "\n",
        "\n",
        "        '''print(xco[8],yco[8])\n",
        "        pyautogui.moveTo(xco[8]*3,yco[8]*3)  '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cv2.imshow('MediaPipe Hands', image)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "rxkfyev-Xk5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}